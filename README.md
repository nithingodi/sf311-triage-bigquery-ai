# City311 Multimodal Triage with BigQuery AI

A **SQL-first prototype** that triages San Francisco 311 complaints using **BigQuery AI**:

-   **Generative AI** (`AI.GENERATE`) ‚Üí structured triage (theme, severity, action)
-   **Vector Search** (`ML.GENERATE_EMBEDDING` + `VECTOR_SEARCH`) ‚Üí semantic match to official policy catalog
-   **Multimodal AI** (Object Tables) ‚Üí summarize image-only complaints
-   **Policy Refinement** ‚Üí refine actions to ensure compliance with regulations
-   **Dashboards** ‚Üí coverage, match rates, mismatch corrections

---

## üìå Problem

311 complaints are messy: free-text, often missing details, sometimes just images.
City policy handbooks are dense PDFs. Human triage is slow and inconsistent.

---

## üöÄ Impact

-   **Coverage doubled**: 200 ‚Üí 400 complaints usable (via AI image summaries)
-   **Policy matches up**: 193 ‚Üí 393 (+104% lift)
-   **Match rate improved**: 96.5% ‚Üí 98.3%
-   **Refinement outcomes (317 rows)**:
    -   93% ‚úÖ match
    -   5% ‚ö† mismatch-corrected
    -   2% ‚ùå no policy

---

## üèó Architecture
![Architecture](diagrams/architecture.png)

1.  **Object Tables** ‚Üí summarize complaint images if text is weak/empty
2.  **AI.GENERATE** ‚Üí triage JSON (theme, severity, action)
3.  **ML.GENERATE_EMBEDDING** + `VECTOR_SEARCH` ‚Üí match complaint to official policy
4.  **AI.GENERATE** ‚Üí refine suggested action to align with policy
5.  **Dashboards** ‚Üí coverage, match rates, mismatch corrections

---

## üìÇ Repo Contents

sf311-triage-bigquery-ai/
‚îú‚îÄ‚îÄ diagrams/architecture.png
‚îú‚îÄ‚îÄ exports/ # optional CSVs for visuals
‚îú‚îÄ‚îÄ scripts/
‚îÇ 00_bootstrap.sh
‚îÇ 02_models.sql
‚îÇ 02_views.sql
‚îÇ 03_quality_and_cohorts.sql
‚îÇ 03_image_summaries.sql
‚îÇ 04_case_summaries.sql
‚îÇ 04_triage_generate_v2.sql
‚îÇ 04a_eda_theme_coverage.sql # optional
‚îÇ 05_label_taxonomy.sql
‚îÇ 05_policy_catalog.sql
‚îÇ 05_policy_catalog_upsert.sql
‚îÇ 06_embeddings_and_search_tuned.sql
‚îÇ 07_refine_prep.sql
‚îÇ 07_refinement.sql
‚îÇ 08_dashboards.sql
‚îÇ 09_proto_comparison.sql
‚îú‚îÄ‚îÄ survey.txt
‚îî‚îÄ‚îÄ README.md


---

## üîß Repro Steps

> **Run order (BigQuery SQL Editor or CLI):**

1.  `bash scripts/00_bootstrap.sh`
2.  `02_models.sql`
3.  `02_views.sql`
4.  `03_quality_and_cohorts.sql`
5.  `03_image_summaries.sql`
6.  `04_case_summaries.sql`
7.  `04_triage_generate_v2.sql`
8.  `05_label_taxonomy.sql`
9.  `05_policy_catalog.sql` and `05_policy_catalog_upsert.sql`
10. `06_embeddings_and_search_tuned.sql`
11. `07_refine_prep.sql`
12. `07_refinement.sql`
13. `08_dashboards.sql`
14. `09_proto_comparison.sql`

---

## üìä Visuals for Writeup

-   **Architecture diagram** ‚Üí `diagrams/architecture.png`
-   **Bar chart** (No-AI vs With-AI) ‚Üí query `v_proto_comparison_metrics`
-   **Pie chart** (Alignment split) ‚Üí query `v_alignment_pie`
-   **Mismatch table** (before ‚Üí after) ‚Üí query `v_mismatch_examples`

To export as CSV:

```bash
bq query --nouse_legacy_sql \
  'SELECT * FROM `sf311-triage-2025.sf311.v_proto_comparison_metrics`' > exports/proto_metrics.csv

bq query --nouse_legacy_sql \
  'SELECT * FROM `sf311-triage-2025.sf311.v_alignment_pie`' > exports/alignment_pie.csv

bq query --nouse_legacy_sql \
  'SELECT * FROM `sf311-triage-2025.sf311.v_mismatch_examples`' > exports/mismatch_examples.csv
```
## üìã Submission Checklist
[x] Writeup (Problem, Impact, Architecture, Results, Limitations, Assets)

[x] Public repo/notebook (this repo)

[x] Diagrams & screenshots included in writeup

[x] Survey.txt (answers: 1mo BigQuery AI, 4mo GCP, feedback)

[x] 

## ‚ö†Ô∏è Limitations
Small policy catalog (hand-curated); real deployment needs full code/policy ingestion.

Demo cohort capped at 400 rows (200 text + 200 image) for free-tier credits.

No full streaming pipeline; batch-only for Kaggle scope.

## üìë License
MIT



## To run

```bash
# ==== 0) Set your GCP project & unique bucket ====
MY_PROJECT="<YOUR_GCP_PROJECT_ID>"      # <- replace this
MY_BUCKET="sf311-triage-$RANDOM-data"   # must be globally unique

gcloud config set project "$MY_PROJECT"

# ==== 1) Clone the repo ====
cd ~
git clone https://github.com/nithingodi/sf311-triage-bigquery-ai.git
cd sf311-triage-bigquery-ai

# ==== 2) Patch bootstrap with project & bucket ====
sed -i -E "s|^PROJECT_ID=\"[^\"]*\"|PROJECT_ID=\"$MY_PROJECT\"|" scripts/00_bootstrap.sh
sed -i -E "s|^BUCKET_NAME=\"[^\"]*\"|BUCKET_NAME=\"$MY_BUCKET\"|" scripts/00_bootstrap.sh

# ==== 3) Bootstrap environment ====
bash scripts/00_bootstrap.sh

# ==== 4) Run the pipeline (02 ‚Üí 10) via Makefile ====
make run_all FROM=02

# ==== 5) (Optional) Export charts ====
mkdir -p exports
bq query --nouse_legacy_sql 'SELECT * FROM `'"$MY_PROJECT"'.sf311.v_proto_comparison_metrics`' > exports/proto_metrics.csv
bq query --nouse_legacy_sql 'SELECT * FROM `'"$MY_PROJECT"'.sf311.v_alignment_pie`'          > exports/alignment_pie.csv
bq query --nouse_legacy_sql 'SELECT * FROM `'"$MY_PROJECT"'.sf311.v_mismatch_examples`'      > exports/mismatch_examples.csv
```

